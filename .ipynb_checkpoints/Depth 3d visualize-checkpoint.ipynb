{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d210d377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\snowy/.cache\\torch\\hub\\intel-isl_MiDaS_master\n",
      "C:\\Users\\snowy\\anaconda3\\envs\\tf\\lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Using cache found in C:\\Users\\snowy/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from sklearn.cluster import DBSCAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0633e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./resource/Images1/1.Bmp\"\n",
    "depth_map = utils.estimate_depth(image_path)\n",
    "cam = utils.create_intrinsic_matrix(depth_map, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18e7af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_with_clustering(points, eps=0.01, min_samples=5, height_threshold=0.01):\n",
    "    \"\"\"군집화를 사용하여 높이를 평탄화합니다.\"\"\"\n",
    "    # x, y 좌표를 사용하여 군집화\n",
    "    X = points[:, :2]\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    clusters = dbscan.fit_predict(X)\n",
    "\n",
    "    # 군집이 -1인 점들은 노이즈로 간주하고 제외\n",
    "    valid_indices = clusters != -1\n",
    "    points_clustered = points[valid_indices]\n",
    "    clusters_valid = clusters[valid_indices]\n",
    "\n",
    "    new_points = []\n",
    "    for cluster_id in np.unique(clusters_valid):\n",
    "        # 각 군집에 속하는 포인트들을 추출\n",
    "        cluster_points = points_clustered[clusters_valid == cluster_id]\n",
    "\n",
    "        # 군집 내의 높이 분석\n",
    "        z_values = cluster_points[:, 2]\n",
    "        z_range = np.max(z_values) - np.min(z_values)\n",
    "\n",
    "        # 높이 변화가 작으면 평탄화\n",
    "        if z_range < height_threshold:\n",
    "            mean_z = np.mean(z_values)\n",
    "            for point in cluster_points:\n",
    "                new_points.append([point[0], point[1], mean_z])\n",
    "        else:\n",
    "            # 급격한 변화가 있는 경우 원래 높이 유지\n",
    "            for point in cluster_points:\n",
    "                new_points.append(point)\n",
    "\n",
    "    return np.array(new_points)\n",
    "\n",
    "def reconstruct_3d_with_grid(depth_map, intrinsic_matrix, image_path):\n",
    "    points = utils.generate_point_cloud(depth_map, intrinsic_matrix)\n",
    "    points = utils.preprocess_point_cloud(points, method=\"normalize\")\n",
    "    points = flatten_with_clustering(points, eps=0.02, min_samples=10, height_threshold=0.02)\n",
    "    del depth_map\n",
    "    utils.visualize_point_cloud_with_texture(points, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9df7d4bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mreconstruct_3d_with_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdepth_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 37\u001b[0m, in \u001b[0;36mreconstruct_3d_with_grid\u001b[1;34m(depth_map, intrinsic_matrix, image_path)\u001b[0m\n\u001b[0;32m     35\u001b[0m points \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mgenerate_point_cloud(depth_map, intrinsic_matrix)\n\u001b[0;32m     36\u001b[0m points \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mpreprocess_point_cloud(points, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m points \u001b[38;5;241m=\u001b[39m \u001b[43mflatten_with_clustering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m depth_map\n\u001b[0;32m     39\u001b[0m utils\u001b[38;5;241m.\u001b[39mvisualize_point_cloud_with_texture(points, image_path)\n",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m, in \u001b[0;36mflatten_with_clustering\u001b[1;34m(points, eps, min_samples, height_threshold)\u001b[0m\n\u001b[0;32m      4\u001b[0m X \u001b[38;5;241m=\u001b[39m points[:, :\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m      5\u001b[0m dbscan \u001b[38;5;241m=\u001b[39m DBSCAN(eps\u001b[38;5;241m=\u001b[39meps, min_samples\u001b[38;5;241m=\u001b[39mmin_samples)\n\u001b[1;32m----> 6\u001b[0m clusters \u001b[38;5;241m=\u001b[39m \u001b[43mdbscan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 군집이 -1인 점들은 노이즈로 간주하고 제외\u001b[39;00m\n\u001b[0;32m      9\u001b[0m valid_indices \u001b[38;5;241m=\u001b[39m clusters \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_dbscan.py:470\u001b[0m, in \u001b[0;36mDBSCAN.fit_predict\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    446\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute clusters from a data or distance matrix and predict labels.\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m        Cluster labels. Noisy samples are given the label -1.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\cluster\\_dbscan.py:418\u001b[0m, in \u001b[0;36mDBSCAN.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    416\u001b[0m neighbors_model\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# This has worst case O(n^2) memory complexity\u001b[39;00m\n\u001b[1;32m--> 418\u001b[0m neighborhoods \u001b[38;5;241m=\u001b[39m \u001b[43mneighbors_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mradius_neighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m     n_neighbors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mlen\u001b[39m(neighbors) \u001b[38;5;28;01mfor\u001b[39;00m neighbors \u001b[38;5;129;01min\u001b[39;00m neighborhoods])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neighbors\\_base.py:1276\u001b[0m, in \u001b[0;36mRadiusNeighborsMixin.radius_neighbors\u001b[1;34m(self, X, radius, return_distance, sort_results)\u001b[0m\n\u001b[0;32m   1274\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m   1275\u001b[0m delayed_query \u001b[38;5;241m=\u001b[39m delayed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tree\u001b[38;5;241m.\u001b[39mquery_radius)\n\u001b[1;32m-> 1276\u001b[0m chunked_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1278\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen_even_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1279\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_distance:\n\u001b[0;32m   1281\u001b[0m     neigh_ind, neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mchunked_results))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32msklearn\\\\neighbors\\\\_binary_tree.pxi:1431\u001b[0m, in \u001b[0;36msklearn.neighbors._kd_tree.BinaryTree64.query_radius\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msklearn\\\\neighbors\\\\_binary_tree.pxi:1384\u001b[0m, in \u001b[0;36msklearn.neighbors._kd_tree.BinaryTree64.query_radius\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reconstruct_3d_with_grid(depth_map, cam, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d217fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9109facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_with_clustering(points, eps=0.01, min_samples=5, height_threshold=0.01, batch_size=10000):\n",
    "    \"\"\"군집화를 사용하여 높이를 평탄화합니다 (배치 처리 및 노이즈 처리 개선).\"\"\"\n",
    "    num_points = len(points)\n",
    "    new_points = []\n",
    "\n",
    "    for i in range(0, num_points, batch_size):\n",
    "        batch = points[i:i + batch_size]\n",
    "        X_batch = batch[:, :2]\n",
    "\n",
    "        if len(X_batch) < min_samples: #배치 크기가 min_samples보다 작으면 건너뜀\n",
    "            new_points.extend(batch.tolist())\n",
    "            continue\n",
    "\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        clusters = dbscan.fit_predict(X_batch)\n",
    "\n",
    "        for cluster_id in np.unique(clusters):\n",
    "            # 노이즈 처리 (-1인 클러스터는 다음 단계로 넘어감)\n",
    "            if cluster_id == -1:\n",
    "                noise_points = batch[clusters == -1]\n",
    "                new_points.extend(noise_points.tolist())\n",
    "                continue\n",
    "\n",
    "            cluster_points = batch[clusters == cluster_id]\n",
    "            z_values = cluster_points[:, 2]\n",
    "            z_range = np.max(z_values) - np.min(z_values)\n",
    "\n",
    "            if z_range < height_threshold:\n",
    "                mean_z = np.mean(z_values)\n",
    "                for point in cluster_points:\n",
    "                    new_points.append([point[0], point[1], mean_z])\n",
    "            else:\n",
    "                new_points.extend(cluster_points.tolist())\n",
    "\n",
    "    return np.array(new_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7709d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_3d_with_grid(depth_map, intrinsic_matrix, image_path):\n",
    "    points = utils.generate_point_cloud(depth_map, intrinsic_matrix)\n",
    "    points = utils.preprocess_point_cloud(points, method=\"normalize\")\n",
    "    points = flatten_with_clustering(points, eps=0.02, min_samples=10000, height_threshold=0.000002)\n",
    "    del depth_map\n",
    "    utils.visualize_point_cloud_with_texture(points, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98fbf4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_3d_with_grid(depth_map, cam, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa5bb1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_to_two_levels(points, threshold_ratio=0.1):\n",
    "    \"\"\"높이를 두 개의 레벨로 평탄화합니다.\"\"\"\n",
    "    z_values = points[:, 2]\n",
    "    z_min = np.min(z_values)\n",
    "    z_max = np.max(z_values)\n",
    "    z_range = z_max - z_min\n",
    "\n",
    "    # 높이 임계값 계산 (전체 높이 범위의 threshold_ratio 비율)\n",
    "    threshold = z_min + z_range * threshold_ratio\n",
    "\n",
    "    new_points = points.copy() # 원본 복사본 생성\n",
    "\n",
    "    # 가장 낮은 층에 속하는 포인트 평탄화\n",
    "    low_indices = z_values <= threshold\n",
    "    new_points[low_indices, 2] = z_min\n",
    "\n",
    "    # 가장 높은 층에 속하는 포인트 평탄화\n",
    "    high_indices = z_values >= (z_max - z_range*threshold_ratio)\n",
    "    new_points[high_indices, 2] = z_max\n",
    "\n",
    "    return new_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50ac0502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_3d_with_grid(depth_map, intrinsic_matrix, image_path):\n",
    "    points = utils.generate_point_cloud(depth_map, intrinsic_matrix)\n",
    "    points = utils.preprocess_point_cloud(points, method=\"none\") # 정규화 제거\n",
    "    points = flatten_to_two_levels(points, threshold_ratio=0.01)\n",
    "    utils.visualize_point_cloud_with_texture(points, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c444912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_3d_with_grid(depth_map, cam, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c915120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_to_two_levels(points, threshold_ratio=0.1):\n",
    "    \"\"\"높이를 두 개의 레벨로 평탄화합니다 (중간 높이 유지, 층 연결).\"\"\"\n",
    "    z_values = points[:, 2]\n",
    "    z_min = np.min(z_values)\n",
    "    z_max = np.max(z_values)\n",
    "    z_range = z_max - z_min\n",
    "\n",
    "    if z_range == 0:  # 모든 z 값이 동일한 경우 처리\n",
    "        return points\n",
    "\n",
    "    # 임계값 계산\n",
    "    lower_threshold = z_min + z_range * threshold_ratio\n",
    "    upper_threshold = z_max - z_range * threshold_ratio\n",
    "\n",
    "    new_points = points.copy()\n",
    "\n",
    "    # 가장 낮은 층에 속하는 포인트들을 추출\n",
    "    low_indices = z_values <= lower_threshold\n",
    "    low_points = points[low_indices]\n",
    "\n",
    "    # 가장 높은 층에 속하는 포인트들을 추출\n",
    "    high_indices = z_values >= upper_threshold\n",
    "    high_points = points[high_indices]\n",
    "\n",
    "    # 낮은 층이 존재할 경우, 해당 층의 최대 높이로 평탄화\n",
    "    if len(low_points) > 0:\n",
    "        max_low_z = np.max(low_points[:, 2])\n",
    "        new_points[low_indices, 2] = max_low_z\n",
    "\n",
    "    # 높은 층이 존재할 경우, 해당 층의 최소 높이로 평탄화\n",
    "    if len(high_points) > 0:\n",
    "        min_high_z = np.min(high_points[:, 2])\n",
    "        new_points[high_indices, 2] = min_high_z\n",
    "\n",
    "    return new_points\n",
    "\n",
    "def reconstruct_3d_with_grid(depth_map, intrinsic_matrix, image_path):\n",
    "    points = utils.generate_point_cloud(depth_map, intrinsic_matrix)\n",
    "    points = utils.preprocess_point_cloud(points, method=\"normalize\") # 정규화 제거\n",
    "    points = flatten_to_two_levels(points, threshold_ratio=0.15) # threshold_ratio 값 조정\n",
    "    utils.visualize_point_cloud_with_texture(points, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c97bec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_3d_with_grid(depth_map, cam, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc12c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ebf863a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c05c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6360de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
